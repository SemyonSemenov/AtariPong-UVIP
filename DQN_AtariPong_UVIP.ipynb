{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN Atari-Pong UVIP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "313ff0b1e9194a7a8028ae79388210aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34f33ea9cea04104bc53cd312fb1e1a9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_884fe5487c9d4d29b7a20f5e944fad25",
              "IPY_MODEL_741ebe8649544e2b9d9fb6af66467ba4"
            ]
          }
        },
        "34f33ea9cea04104bc53cd312fb1e1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "884fe5487c9d4d29b7a20f5e944fad25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_691a9b561cc849dda924866f4108e74d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68b6978f6db24da69ba9f70714e36563"
          }
        },
        "741ebe8649544e2b9d9fb6af66467ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cd63f70d0a154b7082ee3bbc7d97dae9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:31&lt;00:00,  7.86s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9dca7c2041f45fd859dc5d2d386e9a2"
          }
        },
        "691a9b561cc849dda924866f4108e74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68b6978f6db24da69ba9f70714e36563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd63f70d0a154b7082ee3bbc7d97dae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9dca7c2041f45fd859dc5d2d386e9a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4AS7njD7iL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f548ea-abb0-4948-b141-80a5aed028e8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug  5 21:09:14 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEmya8oGOBRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df9f5ec-abe3-49c8-fa64-672313fb6fd9"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "        \n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/atari_wrappers.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/utils.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/replay_buffer.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/week04_approx_rl/framebuffer.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D98CddQuwKG"
      },
      "source": [
        "import gym\n",
        "import cv2\n",
        "\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import deque"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rGMlN2uzgk"
      },
      "source": [
        "ENVIRONMENT = \"PongDeterministic-v4\"\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#SAVE_MODELS = True  # Save models to file so you can test later\n",
        "MODEL_PATH = \"./pong-cnn-\"  # Models path for saving or loading\n",
        "SAVE_MODEL_INTERVAL = 10  # Save models at every X epoch\n",
        "#TRAIN_MODEL = True  # Train model while playing (Make it False when testing a model)\n",
        "\n",
        "SAVE_MODELS = False\n",
        "TRAIN_MODEL = False\n",
        "LOAD_MODEL_FROM_FILE = True\n",
        "LOAD_FILE_EPISODE = 800\n",
        "\n",
        "#LOAD_MODEL_FROM_FILE = False  # Load model from file\n",
        "#LOAD_FILE_EPISODE = 0  # Load Xth episode from file\n",
        "\n",
        "BATCH_SIZE = 64  # Minibatch size that select randomly from mem for train nets\n",
        "MAX_EPISODE = 100000  # Max episode\n",
        "MAX_STEP = 100000  # Max step size for one episode\n",
        "\n",
        "MAX_MEMORY_LEN = 50000  # Max memory len\n",
        "MIN_MEMORY_LEN = 40000  # Min memory len before start train\n",
        "\n",
        "GAMMA = 0.97  # Discount rate\n",
        "ALPHA = 0.00025  # Learning rate\n",
        "EPSILON_DECAY = 0.99  # Epsilon decay rate by step\n",
        "\n",
        "RENDER_GAME_WINDOW = False  # Opens a new window to render the game (Won't work on colab default)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxF5-bzUu1q-"
      },
      "source": [
        "class DuelCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN with Duel Algo. https://arxiv.org/abs/1511.06581\n",
        "    \"\"\"\n",
        "    def __init__(self, h, w, output_size):\n",
        "        super(DuelCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=4,  out_channels=32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        convw, convh = self.conv2d_size_calc(w, h, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        convw, convh = self.conv2d_size_calc(convw, convh, kernel_size=3, stride=1)\n",
        "\n",
        "        linear_input_size = convw * convh * 64  # Last conv layer's out sizes\n",
        "\n",
        "        # Action layer\n",
        "        self.Alinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "        self.Alrelu = nn.LeakyReLU()  # Linear 1 activation funct\n",
        "        self.Alinear2 = nn.Linear(in_features=128, out_features=output_size)\n",
        "\n",
        "        # State Value layer\n",
        "        self.Vlinear1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
        "        self.Vlrelu = nn.LeakyReLU()  # Linear 1 activation funct\n",
        "        self.Vlinear2 = nn.Linear(in_features=128, out_features=1)  # Only 1 node\n",
        "\n",
        "    def conv2d_size_calc(self, w, h, kernel_size=5, stride=2):\n",
        "        \"\"\"\n",
        "        Calcs conv layers output image sizes\n",
        "        \"\"\"\n",
        "        next_w = (w - (kernel_size - 1) - 1) // stride + 1\n",
        "        next_h = (h - (kernel_size - 1) - 1) // stride + 1\n",
        "        return next_w, next_h\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten every batch\n",
        "\n",
        "        Ax = self.Alrelu(self.Alinear1(x))\n",
        "        Ax = self.Alinear2(Ax)  # No activation on last layer\n",
        "\n",
        "        Vx = self.Vlrelu(self.Vlinear1(x))\n",
        "        Vx = self.Vlinear2(Vx)  # No activation on last layer\n",
        "\n",
        "        q = Vx + (Ax - Ax.mean())\n",
        "\n",
        "        return q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plT51MPbu5U5"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, environment):\n",
        "        \"\"\"\n",
        "        Hyperparameters definition for Agent\n",
        "        \"\"\"\n",
        "        # State size for breakout env. SS images (210, 160, 3). Used as input size in network\n",
        "        self.state_size_h = environment.observation_space.shape[0]\n",
        "        self.state_size_w = environment.observation_space.shape[1]\n",
        "        self.state_size_c = environment.observation_space.shape[2]\n",
        "\n",
        "        # Activation size for breakout env. Used as output size in network\n",
        "        self.action_size = environment.action_space.n\n",
        "\n",
        "        # Image pre process params\n",
        "        self.target_h = 80  # Height after process\n",
        "        self.target_w = 64  # Widht after process\n",
        "\n",
        "        self.crop_dim = [20, self.state_size_h, 0, self.state_size_w]  # Cut 20 px from top to get rid of the score table\n",
        "\n",
        "        # Trust rate to our experiences\n",
        "        self.gamma = GAMMA  # Discount coef for future predictions\n",
        "        self.alpha = ALPHA  # Learning Rate\n",
        "\n",
        "        # After many experinces epsilon will be 0.05\n",
        "        # So we will do less Explore more Exploit\n",
        "        self.epsilon = 1  # Explore or Exploit\n",
        "        self.epsilon_decay = EPSILON_DECAY  # Adaptive Epsilon Decay Rate\n",
        "        self.epsilon_minimum = 0.05  # Minimum for Explore\n",
        "\n",
        "        # Deque holds replay mem.\n",
        "        self.memory = deque(maxlen=MAX_MEMORY_LEN)\n",
        "\n",
        "        # Create two model for DDQN algorithm\n",
        "        self.online_model = DuelCNN(h=self.target_h, w=self.target_w, output_size=self.action_size).to(DEVICE)\n",
        "        self.target_model = DuelCNN(h=self.target_h, w=self.target_w, output_size=self.action_size).to(DEVICE)\n",
        "        self.target_model.load_state_dict(self.online_model.state_dict())\n",
        "        self.target_model.eval()\n",
        "\n",
        "        # Adam used as optimizer\n",
        "        self.optimizer = optim.Adam(self.online_model.parameters(), lr=self.alpha)\n",
        "\n",
        "    def preProcess(self, image):\n",
        "        \"\"\"\n",
        "        Process image crop resize, grayscale and normalize the images\n",
        "        \"\"\"\n",
        "        frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # To grayscale\n",
        "        frame = frame[self.crop_dim[0]:self.crop_dim[1], self.crop_dim[2]:self.crop_dim[3]]  # Cut 20 px from top\n",
        "        frame = cv2.resize(frame, (self.target_w, self.target_h))  # Resize\n",
        "        frame = frame.reshape(self.target_w, self.target_h) / 255  # Normalize\n",
        "\n",
        "        return frame\n",
        "\n",
        "    def act(self, state):\n",
        "        \"\"\"\n",
        "        Get state and do action\n",
        "        Two option can be selectedd if explore select random action\n",
        "        if exploit ask nnet for action\n",
        "        \"\"\"\n",
        "\n",
        "        act_protocol = 'Explore' if random.uniform(0, 1) <= self.epsilon else 'Exploit'\n",
        "\n",
        "        if act_protocol == 'Explore':\n",
        "            action = random.randrange(self.action_size)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state = torch.tensor(state, dtype=torch.float, device=DEVICE).unsqueeze(0)\n",
        "                q_values = self.online_model.forward(state)  # (1, action_size)\n",
        "                action = torch.argmax(q_values).item()  # Returns the indices of the maximum value of all elements\n",
        "\n",
        "        return action\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Train neural nets with replay memory\n",
        "        returns loss and max_q val predicted from online_net\n",
        "        \"\"\"\n",
        "        if len(agent.memory) < MIN_MEMORY_LEN:\n",
        "            loss, max_q = [0, 0]\n",
        "            return loss, max_q\n",
        "        # We get out minibatch and turn it to numpy array\n",
        "        state, action, reward, next_state, done = zip(*random.sample(self.memory, BATCH_SIZE))\n",
        "\n",
        "        # Concat batches in one array\n",
        "        # (np.arr, np.arr) ==> np.BIGarr\n",
        "        state = np.concatenate(state)\n",
        "        next_state = np.concatenate(next_state)\n",
        "\n",
        "        # Convert them to tensors\n",
        "        state = torch.tensor(state, dtype=torch.float, device=DEVICE)\n",
        "        next_state = torch.tensor(next_state, dtype=torch.float, device=DEVICE)\n",
        "        action = torch.tensor(action, dtype=torch.long, device=DEVICE)\n",
        "        reward = torch.tensor(reward, dtype=torch.float, device=DEVICE)\n",
        "        done = torch.tensor(done, dtype=torch.float, device=DEVICE)\n",
        "\n",
        "        # Make predictions\n",
        "        state_q_values = self.online_model(state)\n",
        "        next_states_q_values = self.online_model(next_state)\n",
        "        next_states_target_q_values = self.target_model(next_state)\n",
        "\n",
        "        # Find selected action's q_value\n",
        "        selected_q_value = state_q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
        "        # Get indice of the max value of next_states_q_values\n",
        "        # Use that indice to get a q_value from next_states_target_q_values\n",
        "        # We use greedy for policy So it called off-policy\n",
        "        next_states_target_q_value = next_states_target_q_values.gather(1, next_states_q_values.max(1)[1].unsqueeze(1)).squeeze(1)\n",
        "        # Use Bellman function to find expected q value\n",
        "        expected_q_value = reward + self.gamma * next_states_target_q_value * (1 - done)\n",
        "\n",
        "        # Calc loss with expected_q_value and q_value\n",
        "        loss = (selected_q_value - expected_q_value.detach()).pow(2).mean()\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss, torch.max(state_q_values).item()\n",
        "\n",
        "    def storeResults(self, state, action, reward, nextState, done):\n",
        "        \"\"\"\n",
        "        Store every result to memory\n",
        "        \"\"\"\n",
        "        self.memory.append([state[None, :], action, reward, nextState[None, :], done])\n",
        "\n",
        "    def adaptiveEpsilon(self):\n",
        "        \"\"\"\n",
        "        Adaptive Epsilon means every step\n",
        "        we decrease the epsilon so we do less Explore\n",
        "        \"\"\"\n",
        "        if self.epsilon > self.epsilon_minimum:\n",
        "            self.epsilon *= self.epsilon_decay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOd3uiYfErSl"
      },
      "source": [
        "environment = gym.make(ENVIRONMENT)  # Get env\n",
        "agent = Agent(environment)  # Create Agent\n",
        "\n",
        "if LOAD_MODEL_FROM_FILE:\n",
        "    agent.online_model.load_state_dict(torch.load(MODEL_PATH+str(LOAD_FILE_EPISODE)+\".pkl\"))\n",
        "\n",
        "    with open(MODEL_PATH+str(LOAD_FILE_EPISODE)+'.json') as outfile:\n",
        "        param = json.load(outfile)\n",
        "        agent.epsilon = param.get('epsilon')\n",
        "\n",
        "    startEpisode = LOAD_FILE_EPISODE + 1\n",
        "\n",
        "else:\n",
        "    startEpisode = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve4vYDe3bozg"
      },
      "source": [
        "last_100_ep_reward_arr = []\n",
        "\n",
        "total = []\n",
        "\n",
        "last_100_ep_reward = deque(maxlen=100)  # Last 100 episode rewards\n",
        "total_step = 1  # Cumulkative sum of all steps in episodes\n",
        "for episode in range(startEpisode, MAX_EPISODE):\n",
        "\n",
        "    startTime = time.time()  # Keep time\n",
        "    state = environment.reset()  # Reset env\n",
        "\n",
        "    state = agent.preProcess(state)  # Process image\n",
        "\n",
        "    # Stack state . Every state contains 4 time contionusly frames\n",
        "    # We stack frames like 4 channel image\n",
        "    state = np.stack((state, state, state, state))\n",
        "\n",
        "    total_max_q_val = 0  # Total max q vals\n",
        "    total_reward = 0  # Total reward for each episode\n",
        "    total_loss = 0  # Total loss for each episode\n",
        "    for step in range(MAX_STEP):\n",
        "\n",
        "        if RENDER_GAME_WINDOW:\n",
        "            environment.render()  # Show state visually\n",
        "\n",
        "        # Select and perform an action\n",
        "        action = agent.act(state)  # Act\n",
        "        next_state, reward, done, info = environment.step(action)  # Observe\n",
        "\n",
        "        next_state = agent.preProcess(next_state)  # Process image\n",
        "\n",
        "        # Stack state . Every state contains 4 time contionusly frames\n",
        "        # We stack frames like 4 channel image\n",
        "        next_state = np.stack((next_state, state[0], state[1], state[2]))\n",
        "\n",
        "        # Store the transition in memory\n",
        "        agent.storeResults(state, action, reward, next_state, done)  # Store to mem\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state  # Update state\n",
        "\n",
        "        if TRAIN_MODEL:\n",
        "            # Perform one step of the optimization (on the target network)\n",
        "            loss, max_q_val = agent.train()  # Train with random BATCH_SIZE state taken from mem\n",
        "        else:\n",
        "            loss, max_q_val = [0, 0]\n",
        "\n",
        "        total_loss += loss\n",
        "        total_max_q_val += max_q_val\n",
        "        total_reward += reward\n",
        "        total_step += 1\n",
        "        if total_step % 1000 == 0:\n",
        "            agent.adaptiveEpsilon()  # Decrase epsilon\n",
        "\n",
        "        if done:  # Episode completed\n",
        "            currentTime = time.time()  # Keep current time\n",
        "            time_passed = currentTime - startTime  # Find episode duration\n",
        "            current_time_format = time.strftime(\"%H:%M:%S\", time.gmtime())  # Get current dateTime as HH:MM:SS\n",
        "            epsilonDict = {'epsilon': agent.epsilon}  # Create epsilon dict to save model as file\n",
        "\n",
        "            if SAVE_MODELS and episode % SAVE_MODEL_INTERVAL == 0:  # Save model as file\n",
        "                weightsPath = MODEL_PATH + str(episode) + '.pkl'\n",
        "                epsilonPath = MODEL_PATH + str(episode) + '.json'\n",
        "\n",
        "                torch.save(agent.online_model.state_dict(), weightsPath)\n",
        "                with open(epsilonPath, 'w') as outfile:\n",
        "                    json.dump(epsilonDict, outfile)\n",
        "\n",
        "            if TRAIN_MODEL:\n",
        "                agent.target_model.load_state_dict(agent.online_model.state_dict())  # Update target model\n",
        "\n",
        "            last_100_ep_reward.append(total_reward)\n",
        "            avg_max_q_val = total_max_q_val / step\n",
        "\n",
        "            total.append(total_reward)\n",
        "            last_100_ep_reward_arr.append((episode, np.mean(last_100_ep_reward)))\n",
        "\n",
        "            outStr = \"Episode:{} Time:{} Reward:{:.2f} Loss:{:.2f} Last_100_Avg_Rew:{:.3f} Avg_Max_Q:{:.3f} Epsilon:{:.2f} Duration:{:.2f} Step:{} CStep:{}\".format(\n",
        "                episode, current_time_format, total_reward, total_loss, np.mean(last_100_ep_reward), avg_max_q_val, agent.epsilon, time_passed, step, total_step\n",
        "            )\n",
        "\n",
        "            print(outStr)\n",
        "\n",
        "            if SAVE_MODELS:\n",
        "                outputPath = MODEL_PATH + \"out\" + '.txt'  # Save outStr to file\n",
        "                with open(outputPath, 'a') as outfile:\n",
        "                    outfile.write(outStr+\"\\n\")\n",
        "\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJoTAa89I3tE"
      },
      "source": [
        "**Demonstration:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qC0Hr0pWcFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa800aa-590f-4b70-9736-ee2046c5278e"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fe08bfa5fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJdnwTECXBsf"
      },
      "source": [
        "state = environment.reset()  # Reset env\n",
        "state = agent.preProcess(state)  # Process image\n",
        "state = np.stack((state, state, state, state))\n",
        "\n",
        "env = environment\n",
        "\n",
        "r = 0\n",
        "for i in range(250):\n",
        "  action = agent.act(state)\n",
        "  next_state, reward, done, info = environment.step(action)\n",
        "  screen = env.render(mode='rgb_array')\n",
        "  \n",
        "  next_state = agent.preProcess(next_state) \n",
        "  next_state = np.stack((next_state, state[0], state[1], state[2]))\n",
        "  state = next_state\n",
        "\n",
        "  r += reward\n",
        "  print('reward:', r)\n",
        "  plt.imshow(screen)\n",
        "  ipythondisplay.clear_output(wait=True)\n",
        "  ipythondisplay.display(plt.gcf())\n",
        "\n",
        "  if done:\n",
        "    break\n",
        "    \n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI3y8B1JyR6X"
      },
      "source": [
        "**Main algorithm:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw9JAr5tcaW_"
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "\n",
        "def SampleSupportPoints(n_traj, t_max, env):\n",
        "    traj_t = []\n",
        "    for i in tqdm_notebook(range(n_traj)):\n",
        "        s = env.reset()\n",
        "\n",
        "        traj_t.append(env.unwrapped.clone_state())\n",
        "\n",
        "        s = agent.preProcess(s)  # Process image\n",
        "        s = np.stack((s, s, s, s))\n",
        "        \n",
        "        c = 0\n",
        "        while True:\n",
        "            c += 1\n",
        "            a = agent.act(s)\n",
        "            new_s, r, done, _ = env.step(a)\n",
        "            \n",
        "            if done:\n",
        "              break\n",
        "\n",
        "            if c % t_max == 0:\n",
        "              e_state = env.unwrapped.clone_state()\n",
        "              traj_t.append(e_state)\n",
        "\n",
        "            new_s = agent.preProcess(new_s) \n",
        "            s = np.stack((new_s, s[0], s[1], s[2]))\n",
        "  \n",
        "\n",
        "    return traj_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "313ff0b1e9194a7a8028ae79388210aa",
            "34f33ea9cea04104bc53cd312fb1e1a9",
            "884fe5487c9d4d29b7a20f5e944fad25",
            "741ebe8649544e2b9d9fb6af66467ba4",
            "691a9b561cc849dda924866f4108e74d",
            "68b6978f6db24da69ba9f70714e36563",
            "cd63f70d0a154b7082ee3bbc7d97dae9",
            "a9dca7c2041f45fd859dc5d2d386e9a2"
          ]
        },
        "id": "9A4BbX9tcaZ9",
        "outputId": "d4538b8a-4616-4033-c9df-4b9c8a86ee9f"
      },
      "source": [
        "traj_t = SampleSupportPoints(4, 50, env)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "313ff0b1e9194a7a8028ae79388210aa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA2JeV6Geb7d"
      },
      "source": [
        "def generate_samples_given(env, X_samples, N=1):\n",
        "    device = 'cpu'\n",
        "    rewards0 = []\n",
        "    rewards1 = []\n",
        "    rewards2 = []\n",
        "    rewards3 = []\n",
        "    for X in X_samples:\n",
        "        env.reset()\n",
        "        env.unwrapped.restore_state(X)\n",
        "        _, r0, _, _ = env.step(0)\n",
        "        env.reset()\n",
        "        env.unwrapped.restore_state(X)\n",
        "        _, r1, _, _ = env.step(1)\n",
        "        env.reset()\n",
        "        env.unwrapped.restore_state(X)\n",
        "        _, r2, _, _ = env.step(2)\n",
        "        env.reset()\n",
        "        env.unwrapped.restore_state(X)\n",
        "        _, r3, _, _ = env.step(3)\n",
        "\n",
        "        rewards0.append(r0)\n",
        "        rewards1.append(r1)\n",
        "        rewards2.append(r2)\n",
        "        rewards3.append(r3)\n",
        "\n",
        "    rewards0 = torch.tensor(rewards0, device=device, dtype=torch.float32)\n",
        "    rewards1 = torch.tensor(rewards1, device=device, dtype=torch.float32)\n",
        "    rewards2 = torch.tensor(rewards2, device=device, dtype=torch.float32)\n",
        "    rewards3 = torch.tensor(rewards3, device=device, dtype=torch.float32)\n",
        "    rewards = torch.cat((rewards0[None, :], rewards1[None, :], rewards2[None, :], rewards3[None, :]), axis=0)\n",
        "\n",
        "    return torch.FloatTensor(X_samples), rewards"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDtyIdv8evQ-"
      },
      "source": [
        "X_samples_pi, rewards_pi = generate_samples_given(env, traj_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YEuPqZ3fOT3"
      },
      "source": [
        "def VpiEstimation(env, X_samples, n_samples, gamma):\n",
        "    n_actions = 4\n",
        "    Vpi = []\n",
        "\n",
        "    step = 0\n",
        "    for step in tqdm_notebook(range(len(traj_t))):\n",
        "        average_reward = 0.\n",
        "        for k in range(n_samples):\n",
        "            discounted_reward = 0\n",
        "            env.reset()\n",
        "            env.unwrapped.restore_state(traj_t[step]) #что это такое?\n",
        "            \n",
        "            s, _, _, _ = env.step(0)\n",
        "            s = agent.preProcess(s)  # Process image \n",
        "            s = np.stack((s, s, s, s))\n",
        "            a = agent.act(s)\n",
        "\n",
        "            cur_gamma = 1.\n",
        "\n",
        "            while True:\n",
        "\n",
        "              new_s, r, done, _ = env.step(a)\n",
        "              new_s = agent.preProcess(new_s) \n",
        "              s = np.stack((new_s, s[0], s[1], s[2]))\n",
        "\n",
        "              a = agent.act(s)\n",
        "              discounted_reward += cur_gamma * r\n",
        "              cur_gamma *= gamma\n",
        "\n",
        "              if done:\n",
        "                break\n",
        "\n",
        "            average_reward += discounted_reward\n",
        "\n",
        "        Vpi.append(average_reward / n_samples)\n",
        "        #print(step, average_reward / n_samples)\n",
        "    return torch.tensor(Vpi, dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgaFn6hyfGas"
      },
      "source": [
        "V_pi2 = VpiEstimation(env, traj_t, 1, gamma=0.9999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C4AaQsqxkPw"
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.neighbors import DistanceMetric\n",
        "import sklearn\n",
        "from tqdm import trange \n",
        "from IPython.display import display\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWnV_wqqhXWL"
      },
      "source": [
        "def getMonteCarloUpperBounds(env, X_samples, rewards, V_pi, k=4, total_steps=50, M1=15, M2=15, gamma=0.99):\n",
        "    \"\"\"\n",
        "    0,1,2,3 means action \n",
        "    \"\"\"\n",
        "    max_grad_norm = 5000\n",
        "    loss_history = []\n",
        "    grad_norm_history = []\n",
        "    eval_freq = 1\n",
        "    device = 'cpu'\n",
        "\n",
        "    #state_dim, n_actions = env.observation_space.shape, env.action_space.n\n",
        "    state_dim, n_actions = env.observation_space.shape, 4\n",
        "    # X_samples, rewards = generate_samples_uniform(env, 2000)\n",
        "    #N = X_samples.shape[0]\n",
        "    N = len(X_samples)\n",
        "    neigh = NearestNeighbors(n_neighbors=5, algorithm='kd_tree', leaf_size=30, n_jobs=-1)\n",
        "    #neigh.fit(X_samples.tolist())\n",
        "    neigh.fit(X_samples)\n",
        "    rewards = rewards.reshape(n_actions, N, 1)\n",
        "    # V_pi = VpiEstimation(X_samples, policy)\n",
        "    V_up = torch.clone(V_pi) + 7\n",
        "    #perm = torch.randperm(X_samples.size(0))\n",
        "    perm = torch.randperm(N)\n",
        "    idx = perm[:50] #for output\n",
        "    #idx = range(N)\n",
        "    N_states = 50\n",
        "    samples = np.array(X_samples)[idx] #for output\n",
        "    single_sample = np.random.randint(0, len(X_samples), size=1)\n",
        "    upper_bound_sample = []\n",
        "    # print(X_samples[0])\n",
        "    # assert False\n",
        "    upper_list = [V_up.numpy()]\n",
        "    norm_list_upper = []\n",
        "    step = 0\n",
        "    YX0 = []\n",
        "    YX1 = []\n",
        "    YX2 = []\n",
        "    YX3 = []\n",
        "    for i in range(N):\n",
        "        YX0j = []\n",
        "        YX1j = []\n",
        "        YX2j = []\n",
        "        YX3j = []\n",
        "        for j in range(M1):\n",
        "            env.reset()\n",
        "            env.unwrapped.restore_state(X_samples[i])\n",
        "            YXi0, _, _, _ = env.step(0)\n",
        "            YXi0 = env.unwrapped.clone_state()\n",
        "\n",
        "            env.reset()\n",
        "            env.unwrapped.restore_state(X_samples[i])\n",
        "            YXi1, _, _, _ = env.step(1)\n",
        "            YXi1 = env.unwrapped.clone_state()\n",
        "            \n",
        "            env.reset()\n",
        "            env.unwrapped.restore_state(X_samples[i])\n",
        "            YXi2, _, _, _ = env.step(2)\n",
        "            YXi2 = env.unwrapped.clone_state()\n",
        "\n",
        "            env.reset()\n",
        "            env.unwrapped.restore_state(X_samples[i])\n",
        "            YXi3, _, _, _ = env.step(3)\n",
        "            YXi3 = env.unwrapped.clone_state()\n",
        "\n",
        "            YX0j.append(YXi0)\n",
        "            YX1j.append(YXi1)\n",
        "            YX2j.append(YXi2)\n",
        "            YX3j.append(YXi3)\n",
        "\n",
        "        YX0.append(YX0j)\n",
        "        YX1.append(YX1j)\n",
        "        YX2.append(YX2j)\n",
        "        YX3.append(YX3j)\n",
        "\n",
        "    YX0 = torch.tensor(YX0, device=device, dtype=torch.float32)\n",
        "    YX1 = torch.tensor(YX1, device=device, dtype=torch.float32)\n",
        "    YX2 = torch.tensor(YX2, device=device, dtype=torch.float32)\n",
        "    YX3 = torch.tensor(YX3, device=device, dtype=torch.float32)\n",
        "\n",
        "    Yxa_M1 = torch.cat((YX0[None, :, :, :], YX1[None, :, :, :], YX2[None, :, :, :], YX3[None, :, :, :]), axis=0)\n",
        "    _, idxes_neigh1 = neigh.kneighbors(torch.flatten(Yxa_M1, end_dim=2).numpy().tolist())\n",
        "    V_pi1 = V_pi[torch.tensor(idxes_neigh1)].mean(dim=-1).reshape(n_actions, N, M1)\n",
        "    V_mean = torch.mean(V_pi1, dim=-1) #same shape as rewards\n",
        "    V_mean = V_mean.reshape(n_actions, N, 1)\n",
        "    with trange(step, total_steps + 1) as progress_bar:\n",
        "        for step in progress_bar:\n",
        "            YX0 = []\n",
        "            YX1 = []\n",
        "            YX2 = []\n",
        "            YX3 = []\n",
        "            for i in range(N):\n",
        "                YX0j = []\n",
        "                YX1j = []\n",
        "                YX2j = []\n",
        "                YX3j = []\n",
        "                for j in range(M2):\n",
        "                    env.reset()\n",
        "                    env.unwrapped.restore_state(X_samples[i])\n",
        "                    YXi0, _, _, _ = env.step(0)\n",
        "                    YXi0 = env.unwrapped.clone_state()\n",
        "\n",
        "                    env.reset()\n",
        "                    env.unwrapped.restore_state(X_samples[i])\n",
        "                    YXi1, _, _, _ = env.step(1)\n",
        "                    YXi1 = env.unwrapped.clone_state()\n",
        "            \n",
        "                    env.reset()\n",
        "                    env.unwrapped.restore_state(X_samples[i])\n",
        "                    YXi2, _, _, _ = env.step(2)\n",
        "                    YXi2 = env.unwrapped.clone_state()\n",
        "\n",
        "                    env.reset()\n",
        "                    env.unwrapped.restore_state(X_samples[i])\n",
        "                    YXi3, _, _, _ = env.step(3)\n",
        "                    YXi3 = env.unwrapped.clone_state()\n",
        "\n",
        "                    YX0j.append(YXi0)\n",
        "                    YX1j.append(YXi1)\n",
        "                    YX2j.append(YXi2)\n",
        "                    YX3j.append(YXi3)\n",
        "\n",
        "                YX0.append(YX0j)\n",
        "                YX1.append(YX1j)\n",
        "                YX2.append(YX2j)\n",
        "                YX3.append(YX3j)\n",
        "\n",
        "            YX0 = torch.tensor(YX0, device=device, dtype=torch.float32)\n",
        "            YX1 = torch.tensor(YX1, device=device, dtype=torch.float32)\n",
        "            YX2 = torch.tensor(YX2, device=device, dtype=torch.float32)\n",
        "            YX3 = torch.tensor(YX3, device=device, dtype=torch.float32)\n",
        "            Yxa_M2 = torch.cat((YX0[None, :, :, :], YX1[None, :, :, :], YX2[None, :, :, :], YX3[None, :, :, :]), axis=0)\n",
        "            #Yxa has shape (2, N, M1 + M2, 4)\n",
        "            _, idxes_neigh2 = neigh.kneighbors(torch.flatten(Yxa_M2, end_dim=2).numpy().tolist())\n",
        "            V_pi2 = V_pi[torch.tensor(idxes_neigh2)].mean(dim=-1).reshape(n_actions, N, M2)\n",
        "            V_k = V_up[torch.tensor(idxes_neigh2)].mean(dim=-1).reshape(n_actions, N, M2)\n",
        "\n",
        "            M = V_pi2 - V_mean\n",
        "            # EM = torch.mean(M, dim=-1)\n",
        "            # DM = torch.sum(M**2, dim=-1) / (M.shape[-1] - 1)\n",
        "            #M has shape (n_actions, N, M2)\n",
        "            V_up = (rewards + gamma * (V_k - M)).max(dim=0)[0].mean(dim=-1)\n",
        "\n",
        "            if step % eval_freq == 0:\n",
        "                clear_output(True)\n",
        "                plt.figure(figsize=(15, 10))\n",
        "                plt.subplot(121)\n",
        "                lower = V_pi[idx].numpy()\n",
        "                upper = V_up[idx].numpy()\n",
        "                upper_list.append(upper)\n",
        "                upper_bound_sample.append(V_up[single_sample])\n",
        "                upper_plot = np.repeat(upper.reshape(-1, 1), repeats=2, axis=1).reshape(-1)\n",
        "                lower_plot = np.repeat(lower.reshape(-1, 1), repeats=2, axis=1).reshape(-1)\n",
        "                states_plot = np.concatenate((np.arange(N_states).reshape(-1,1),\n",
        "                                          (np.arange(N_states)+1).reshape(-1,1)), axis=1).reshape(-1)\n",
        "                plt.fill_between(states_plot, lower_plot, upper_plot, alpha=0.3,\n",
        "                            edgecolor='k', linestyle='-')\n",
        "                plt.plot(states_plot, upper_plot, 'b')\n",
        "                plt.legend(loc=\"upper left\", fontsize=14)\n",
        "                plt.xlabel(\"State\", fontsize=25)\n",
        "                #plt.xticks(np.arange(N_states + 1))\n",
        "                plt.xticks(size = 15)\n",
        "                plt.yticks(size = 15)   \n",
        "                plt.title(\"Upper and Lower bounds\", fontsize = 30)\n",
        "\n",
        "\n",
        "                plt.subplot(122)\n",
        "                if step >= 1:\n",
        "                    norm_upper = np.linalg.norm(upper_list[-2] - upper_list[-1])\n",
        "                    norm_list_upper.append(norm_upper)\n",
        "                    plt.plot(norm_list_upper)\n",
        "                    plt.title(\"Upper norm\", fontsize = 30)\n",
        "                    plt.xticks(size = 15)\n",
        "                    plt.yticks(size = 15)\n",
        "                plt.show()\n",
        "                if step == total_steps - 1:\n",
        "                    plt.savefig('pic1.png')\n",
        "                # clear_output(True)\n",
        "                # plt.figure(figsize=[16, 9])\n",
        "\n",
        "                # assert not np.isnan(loss_history[-1])\n",
        "                # plt.subplot(1, 2, 1)\n",
        "                # plt.title(\"loss history\")\n",
        "                # # plt.plot(utils.smoothen(loss_history))\n",
        "                # plt.plot(loss_history)\n",
        "                # plt.grid()\n",
        "\n",
        "                # plt.subplot(1, 2, 2)\n",
        "                # plt.title(\"Grad norm history\")\n",
        "                # # plt.plot(utils.smoothen(grad_norm_history))\n",
        "                # plt.plot(grad_norm_history)\n",
        "                # plt.grid()\n",
        "                # plt.show()\n",
        "\n",
        "\n",
        "    return V_up, V_pi, X_samples.numpy(), upper_bound_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t01JjydwxAq8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "outputId": "95e4764f-b2e7-41b0-8711-2e9fa75ab4c4"
      },
      "source": [
        "V_up, V_pi, samples, upper_bound_sample = getMonteCarloUpperBounds(env, traj_t, rewards_pi, V_pi2, gamma=0.9999)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 51/51 [1:12:48<00:00, 85.65s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-6a5af8c2095a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mV_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMonteCarloUpperBounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_pi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-e19f58183edd>\u001b[0m in \u001b[0;36mgetMonteCarloUpperBounds\u001b[0;34m(env, X_samples, rewards, V_pi, k, total_steps, M1, M2, gamma)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mV_up\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
          ]
        }
      ]
    }
  ]
}